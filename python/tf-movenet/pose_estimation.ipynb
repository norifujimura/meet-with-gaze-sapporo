{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "506df9ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/GitHub/meet-with-gaze-sapporo/python/tf-movenet/ml/classifier.py:25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m   \u001b[38;5;66;03m# Import TFLite interpreter from tflite_runtime package if it's available.\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_runtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interpreter\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;66;03m# If not, fallback to use the TFLite interpreter from the full TF package.\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tflite_runtime'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Classifier\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Movenet\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MoveNetMultiPose\n",
      "File \u001b[0;32m~/Documents/GitHub/meet-with-gaze-sapporo/python/tf-movenet/ml/__init__.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124;03m\"\"\"Module contains pose estimation and pose classification implementations.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassifier\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Classifier\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmovenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Movenet\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmovenet_multipose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MoveNetMultiPose\n",
      "File \u001b[0;32m~/Documents/GitHub/meet-with-gaze-sapporo/python/tf-movenet/ml/classifier.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtflite_runtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterpreter\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interpreter\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     27\u001b[0m   \u001b[38;5;66;03m# If not, fallback to use the TFLite interpreter from the full TF package.\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m   \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     29\u001b[0m   Interpreter \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlite\u001b[38;5;241m.\u001b[39mInterpreter\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# pylint: enable=g-import-not-at-top\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "# Copyright 2021 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Main script to run pose classification and pose estimation.\"\"\"\n",
    "import argparse\n",
    "import logging\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "from ml import Classifier\n",
    "from ml import Movenet\n",
    "from ml import MoveNetMultiPose\n",
    "from ml import Posenet\n",
    "import utils\n",
    "\n",
    "\n",
    "def run(estimation_model: str, tracker_type: str, classification_model: str,\n",
    "        label_file: str, camera_id: int, width: int, height: int) -> None:\n",
    "  \"\"\"Continuously run inference on images acquired from the camera.\n",
    "\n",
    "  Args:\n",
    "    estimation_model: Name of the TFLite pose estimation model.\n",
    "    tracker_type: Type of Tracker('keypoint' or 'bounding_box').\n",
    "    classification_model: Name of the TFLite pose classification model.\n",
    "      (Optional)\n",
    "    label_file: Path to the label file for the pose classification model. Class\n",
    "      names are listed one name per line, in the same order as in the\n",
    "      classification model output. See an example in the yoga_labels.txt file.\n",
    "    camera_id: The camera id to be passed to OpenCV.\n",
    "    width: The width of the frame captured from the camera.\n",
    "    height: The height of the frame captured from the camera.\n",
    "  \"\"\"\n",
    "\n",
    "  # Notify users that tracker is only enabled for MoveNet MultiPose model.\n",
    "  if tracker_type and (estimation_model != 'movenet_multipose'):\n",
    "    logging.warning(\n",
    "        'No tracker will be used as tracker can only be enabled for '\n",
    "        'MoveNet MultiPose model.')\n",
    "\n",
    "  # Initialize the pose estimator selected.\n",
    "  if estimation_model in ['movenet_lightning', 'movenet_thunder']:\n",
    "    pose_detector = Movenet(estimation_model)\n",
    "  elif estimation_model == 'posenet':\n",
    "    pose_detector = Posenet(estimation_model)\n",
    "  elif estimation_model == 'movenet_multipose':\n",
    "    pose_detector = MoveNetMultiPose(estimation_model, tracker_type)\n",
    "  else:\n",
    "    sys.exit('ERROR: Model is not supported.')\n",
    "\n",
    "  # Variables to calculate FPS\n",
    "  counter, fps = 0, 0\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Start capturing video input from the camera\n",
    "  cap = cv2.VideoCapture(camera_id)\n",
    "  cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "  cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "  # Visualization parameters\n",
    "  row_size = 20  # pixels\n",
    "  left_margin = 24  # pixels\n",
    "  text_color = (0, 0, 255)  # red\n",
    "  font_size = 1\n",
    "  font_thickness = 1\n",
    "  classification_results_to_show = 3\n",
    "  fps_avg_frame_count = 10\n",
    "  keypoint_detection_threshold_for_classifier = 0.1\n",
    "  classifier = None\n",
    "\n",
    "  # Initialize the classification model\n",
    "  if classification_model:\n",
    "    classifier = Classifier(classification_model, label_file)\n",
    "    classification_results_to_show = min(classification_results_to_show,\n",
    "                                         len(classifier.pose_class_names))\n",
    "\n",
    "  # Continuously capture images from the camera and run inference\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success:\n",
    "      sys.exit(\n",
    "          'ERROR: Unable to read from webcam. Please verify your webcam settings.'\n",
    "      )\n",
    "\n",
    "    counter += 1\n",
    "    image = cv2.flip(image, 1)\n",
    "\n",
    "    if estimation_model == 'movenet_multipose':\n",
    "      # Run pose estimation using a MultiPose model.\n",
    "      list_persons = pose_detector.detect(image)\n",
    "    else:\n",
    "      # Run pose estimation using a SinglePose model, and wrap the result in an\n",
    "      # array.\n",
    "      list_persons = [pose_detector.detect(image)]\n",
    "\n",
    "    # Draw keypoints and edges on input image\n",
    "    image = utils.visualize(image, list_persons)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Calculate the FPS\n",
    "    if counter % fps_avg_frame_count == 0:\n",
    "      end_time = time.time()\n",
    "      fps = fps_avg_frame_count / (end_time - start_time)\n",
    "      start_time = time.time()\n",
    "\n",
    "    # Show the FPS\n",
    "    fps_text = 'FPS = ' + str(int(fps))\n",
    "    text_location = (left_margin, row_size)\n",
    "    cv2.putText(image, fps_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                font_size, text_color, font_thickness)\n",
    "\n",
    "    # Stop the program if the ESC key is pressed.\n",
    "    if cv2.waitKey(1) == 27:\n",
    "      break\n",
    "    cv2.imshow(estimation_model, image)\n",
    "\n",
    "  cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "    \n",
    "run('movenet_lightning', 'keypoint',None, None,\n",
    "      int(0), 800, 600)\n",
    "\n",
    "def main():\n",
    "  parser = argparse.ArgumentParser(\n",
    "      formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "  parser.add_argument(\n",
    "      '--model',\n",
    "      help='Name of estimation model.',\n",
    "      required=False,\n",
    "      default='movenet_lightning')\n",
    "  parser.add_argument(\n",
    "      '--tracker',\n",
    "      help='Type of tracker to track poses across frames.',\n",
    "      required=False,\n",
    "      default='keypoint') #bounding_box,keypoint\n",
    "  parser.add_argument(\n",
    "      '--classifier', help='Name of classification model.', required=False)\n",
    "  parser.add_argument(\n",
    "      '--label_file',\n",
    "      help='Label file for classification.',\n",
    "      required=False,\n",
    "      default='labels.txt')\n",
    "  parser.add_argument(\n",
    "      '--cameraId', help='Id of camera.', required=False, default=0)\n",
    "  parser.add_argument(\n",
    "      '--frameWidth',\n",
    "      help='Width of frame to capture from camera.',\n",
    "      required=False,\n",
    "      default=800)\n",
    "  parser.add_argument(\n",
    "      '--frameHeight',\n",
    "      help='Height of frame to capture from camera.',\n",
    "      required=False,\n",
    "      default=600)\n",
    "  args = parser.parse_args()\n",
    "\n",
    "  run(args.model, args.tracker, args.classifier, args.label_file,\n",
    "      int(args.cameraId), args.frameWidth, args.frameHeight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc401b58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
